from collections import Counter
import numpy as np
import pandas as pd

from .noun_phrases_detection import extract_NP_text, convert_to_text

def char_names_predictions(face_predictions: list[list[list[str, np.array]]]) -> list[list[str]]:
    """_summary_

    Args:
        face_predictions (list[list[list[str, np.array]]]): the face preditions generated by the face recognition functionality

    Returns:
        list[list[str]]: a processed list with only the labels without the bounding boxes
    """

    # first extract only the character names as needed
    char_names  = [[l[0] for l in p] for p in face_predictions]
    return char_names


def build_captions_class_matrix(filtered_nps: list[list[str]], face_predictions: list[list[str]]) -> tuple[Counter, Counter]:
    """This function computes the needed statistics to associate a score for each pair of noun phrase and predicted label

    Args:
        filtered_nps (list[list[str]]): the i-th element represents a list of noun phrases extracted from the i-th text
        face_predictions (list[list[str]]): the i-th elements represents a list of face lables predicted on the i-th image (associated with the i-th text)

    Returns:
        tuple[Counter, Counter]: class_np_counter: the class frequency of each word in the given noun phrases, 
        np_class_counter: the set of classes seen with each word in the given noun phrases 
    """

    class_np_counter = Counter() # to save the frequency of each np with each class
    np_class_counter = {} # to save which classes each np was seen with: used mainly for the inverse document frequency component
    
    for np_list, pred_list in zip(filtered_nps, face_predictions): # np_list represents a list of noun phrases for a single caption

        # each class in the predictions should be associated with any noun phrases in the np_list
        for char_pred in pred_list:
            
            if char_pred not in class_np_counter:
                class_np_counter[char_pred] = Counter() # a dictionary for each of the classes        
            
            # iterate through the noun phrases: 
            for np in np_list:
                # increase the frequency of each term in the caption, in the dictionary associated with the class
                class_np_counter[char_pred].update(dict([(word, 1) for word in np.split(" ")]))
                
                # the current class should be associated with every word in the noun phrase.
                for word in np.split(" "):
                    if word not in np_class_counter:
                        np_class_counter[word] = set() 
                    # add the pred to the list of classes 'word' is associated with 
                    np_class_counter[word].add(char_pred)
            
    return class_np_counter, np_class_counter


def find_decided_captions(filtered_noun_phrases: list[list[str]], face_predictions: list[list[str]])-> tuple[Counter, Counter]:
    """This function executes the same functionality as the previous function with the main difference of considering only pairs of (predictions, noun phrases)
    for which the number of both is equal to one. Such occurences should weight more in the final score of a pair: (np, label)
    Args:
        filtered_nps (list[list[str]]): the i-th element represents a list of noun phrases extracted from the i-th text
        face_predictions (list[list[str]]): the i-th elements represents a list of face lables predicted on the i-th image (associated with the i-th text)

    Returns:
        tuple[Counter, Counter]: class_np_counter: the class frequency of each word in the given noun phrases, 
        np_class_counter: the set of classes seen with each word in the given noun phrases 
    """

    # this function will just return the captions and face_predictions with length 1
    decisive_list =  [(np_list[0], fp[0]) for np_list, fp in zip(filtered_noun_phrases, face_predictions) if len(np_list) == len(fp) == 1]
    
    # convert the list of tuples to 2 lists
    # nps represents a list of strings 
    # predictions: a list of strings
    nps, predictions = list(map(list, zip(*decisive_list))) 
    
    # build a counter to map each class to its decided captions
    decisive_class_np_counter = Counter()

    for np, pred in zip(nps, predictions):

        if pred not in decisive_class_np_counter:
            decisive_class_np_counter[pred] = Counter()

        decisive_class_np_counter[pred].update(dict([(w, 1) for w in np.split(" ")]))

    return decisive_class_np_counter


def np_class_score(noun_phrase: str, class_prediction: str, class_np_counter: Counter, np_class_counter: Counter, decided_class_np: Counter) -> float:
    """This function assigns a score of a give pair: noun_phrase, class_label. It is a customized version of tf-idf representation of a text with respect to a
    given vocabulary and set of documents

    Args:
        noun_phrase (str): a noun phrase that was previously seen in the entire set of noun phrases
        class_prediction (str): a label 
        class_np_counter (Counter): 
        np_class_counter (Counter): 
        decided_class_np (Counter): 

    Returns:
        float: the score of the pair 
    """

    def word_class_score(word: str):        
        try:
            frequency_score = class_np_counter[class_prediction][word]
        except:
            frequency_score = 0
        
        try:
            decided_freq_score = decided_class_np[class_prediction][word]
        except:
            decided_freq_score = 0
        
        numerator = 1 + frequency_score + decided_freq_score
    
        # the denominator: the number of unique classes the word was associated with + 1 
        denominator = 1 + len(np_class_counter[word]) 

        return np.log(numerator / denominator) + 1
    
    words = noun_phrase.split(" ")
    return np.mean([word_class_score(w) for w in words])


def map_np_char_name(noun_phrases: list[str], face_predictions: list[str], class_np_counter: Counter, np_class_counter: Counter, decided_class_np:Counter) -> dict:
    """given a list of noun phrases and a list of labels, this function forms the best pairs (noun phrase, prediction) according to the score functionalitya provided above

    Note: this function does not require two lists of the same size. The resulting mapping will have a length min(length(noun_phrases), len(face_predictions))
    Args:
        noun_phrases (list[str]): list of noun phrases
        face_predictions (list[str]): list of labels
        class_np_counter (Counter): 
        np_class_counter (Counter): 
        decided_class_np (Counter): 

    Returns:
        dict: a mapping between noun phrases and labels
    """
    
    
    # create a dataframe to save the score of each noun phrase with the class predicted
    np_scores = pd.DataFrame(data=[], index=noun_phrases, columns=face_predictions, dtype=float)
    for noun_p in noun_phrases:
        for face_pred in face_predictions:
            np_scores.at[noun_p, face_pred] = np_class_score(noun_p, face_pred, class_np_counter, np_class_counter, decided_class_np)

    mapping = {}
    while not np_scores.empty:
        # first extract the highest score in the table
        max_score = np.amax(np_scores.values)
        
        # locate it
        indices, columns = np.where(np_scores == max_score)
        # extract the corresponding noun phrase and prediction
        best_np = list(np_scores.index)[indices[0]]
        best_pred = list(np_scores.columns)[columns[0]]

        # map the best_face_pred to the best_index
        mapping[best_np] = best_pred
        # remove the index and the face from np_scores
        np_scores.drop(columns=best_pred, index=best_np, inplace=True)

    return mapping    
    

def replace_with_char_names(captions: list[str], face_predictions: list[list[list[str, np.array]]]):
    # first off extract plain names 
    face_predictions = char_names_predictions(face_predictions)
    # extract the nps from the captions
    # nps = extract_NP_text("\n".join(captions), plain_text=False)
    nps = extract_NP_text(captions)

    # first extract the captions as plain text
    plain_nps = [[convert_to_text(t, filter=False) for t in component] for component in nps]

    # extract the filtered version of each caption
    filtered_text_nps = [[convert_to_text(t, filter=True) for t in component] for component in nps]
    # now we have the captions and the predictions ready 
    # time to build the matrix
    class_np_counter, np_class_counter = build_captions_class_matrix(filtered_text_nps, face_predictions)
    # find the decided captions
    decisive_class_np_counter = find_decided_captions(filtered_text_nps, face_predictions)
    # iterate through each of the predictions and captions
    final_captions = []
    
    for np_list_index, (np_list, pred_list) in enumerate(zip(filtered_text_nps, face_predictions)):    
        # map the noun phrase to the suitable class
        mapping = map_np_char_name(np_list, pred_list, class_np_counter, np_class_counter, decisive_class_np_counter)
        
        new_caption = captions[np_list_index]

        # for each pair of noun phrase and prediction
        for np, face_pred in mapping.items():
            # within the different nps in the current noun phrases, find the position 'np'
            np_index = np_list.index(np)
            # determine the exact text to replace 
            text_to_replace = plain_nps[np_list_index][np_index]
            # replace it in the caption
            new_caption = new_caption.replace(text_to_replace, face_pred)

        final_captions.append(new_caption)

    return final_captions


